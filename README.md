# Mini Scikit-Learn

Una implementaciÃ³n simplificada de la funcionalidad central de scikit-learn con fines educativos. Este proyecto replica componentes clave de scikit-learn para demostrar conceptos de aprendizaje automÃ¡tico y prÃ¡cticas de POO en Python.

## ğŸ¯ Objetivos del Proyecto

- **Enfoque Educativo**: Comprender cÃ³mo funciona scikit-learn internamente
- **PrÃ¡ctica de POO en Python**: Implementar patrones de diseÃ±o como mixins, clases abstractas y herencia
- **Pruebas A/B**: Comparar nuestra implementaciÃ³n contra scikit-learn con tolerancias definidas
- **Ciencia Reproducible**: Asegurar resultados consistentes con semillas aleatorias fijas

## ğŸš€ Inicio RÃ¡pido

### Requisitos Previos

```bash
# Instalar dependencias requeridas
pip install numpy pytest scikit-learn
```

O usar nuestro script auxiliar:
```bash
make install
```

### Ejecutar Tests

**Forma fÃ¡cil (recomendada):**
```bash
make test           # Ejecutar todos los tests
make test-quick     # EjecuciÃ³n rÃ¡pida con salida mÃ­nima
make test-ab        # Solo tests de comparaciÃ³n A/B
```

**Formas alternativas:**
```bash
# Usando script de Python
python run_tests.py           # Todos los tests
python run_tests.py ab        # Solo tests A/B

# pytest directo
PYTHONPATH=. python3 -m pytest tests/ -v
```

**Ver todas las opciones:**
```bash
make help
```

## ğŸ“¦ Componentes Implementados

### âœ… DivisiÃ³n de Datos (`model_selection.py`)
- `train_test_split()` con soporte para estratificaciÃ³n
- Preserva las proporciones de clases en datasets desbalanceados
- Muestreo bootstrap con semillas aleatorias reproducibles

### âœ… Preprocesamiento (`preprocessing.py`)
- `MinMaxScaler` con rangos de caracterÃ­sticas configurables
- Maneja caracterÃ­sticas constantes correctamente
- Paridad exacta con `data_min_` y `data_max_` de scikit-learn

### âœ… MÃ©todos de Ensamble (`ensemble.py`)
- `RandomForestClassifier` con agregaciÃ³n bootstrap
- SelecciÃ³n aleatoria de caracterÃ­sticas en cada divisiÃ³n
- VotaciÃ³n por mayorÃ­a para predicciones
- Ãrboles de decisiÃ³n simples con umbrales aleatorios

### âœ… Pipelines (`pipeline.py`)
- `Pipeline` para encadenar transformadores y estimadores
- Flujo automÃ¡tico de datos a travÃ©s de `fit_transform` y `transform`
- Previene fuga de datos usando `transform` (no `fit_transform`) en datos de prueba
- Compatible con todos los transformadores y estimadores

### âœ… Infraestructura Base (`base.py`, `metrics.py`)
- ValidaciÃ³n de entrada (`check_array`, `check_X_y`)
- Clases base y mixins (`BaseEstimator`, `ClassifierMixin`, `TransformerMixin`)
- MÃ©tricas de rendimiento (`accuracy_score`)

## ğŸ§ª Estrategia de Pruebas

Nuestra implementaciÃ³n usa **pruebas A/B** contra scikit-learn para asegurar paridad funcional:

- **DivisiÃ³n de Datos**: Coincidencia exacta de formas, preservaciÃ³n de proporciones (tolerancia de Â±1 muestra)
- **MinMaxScaler**: Coincidencia exacta de `data_min_`/`data_max_`, salida de transform con tolerancia de 1e-8
- **RandomForest**: PrecisiÃ³n dentro de Â±0.25 de scikit-learn (considera diferentes algoritmos de Ã¡rbol)
- **Pipeline**: PrecisiÃ³n en conjunto de prueba dentro de Â±0.20 de scikit-learn
- **Manejo de Errores**: Pruebas negativas exhaustivas para entradas invÃ¡lidas

## ğŸ“Š Ejemplo de Uso

```python
from mini_sklearn.model_selection import train_test_split
from mini_sklearn.preprocessing import MinMaxScaler
from mini_sklearn.ensemble import RandomForestClassifier
from mini_sklearn.pipeline import Pipeline

# Crear datos de ejemplo
import numpy as np
np.random.seed(42)
X = np.random.randn(100, 4)
y = (X[:, 0] + X[:, 1] > 0).astype(int)

# Dividir datos con estratificaciÃ³n
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

# Crear pipeline con escalador y clasificador
pipeline = Pipeline([
    ('scaler', MinMaxScaler(feature_range=(-1, 1))),
    ('clf', RandomForestClassifier(n_estimators=50, random_state=42))
])

# Ajustar pipeline (escala y entrena automÃ¡ticamente)
pipeline.fit(X_train, y_train)

# Evaluar (aplica el escalado automÃ¡ticamente antes de predecir)
print(f"PrecisiÃ³n en Test: {pipeline.score(X_test, y_test):.3f}")

# Hacer predicciones
y_pred = pipeline.predict(X_test)
```

## ğŸ—ï¸ Estructura del Proyecto

```
mini_sklearn/
â”œâ”€â”€ __init__.py           # InicializaciÃ³n del paquete
â”œâ”€â”€ base.py              # Clases base y validaciÃ³n
â”œâ”€â”€ metrics.py           # MÃ©tricas de rendimiento
â”œâ”€â”€ model_selection.py   # Utilidades de divisiÃ³n de datos
â”œâ”€â”€ preprocessing.py     # Transformadores de datos
â”œâ”€â”€ ensemble.py          # MÃ©todos de ensamble
â””â”€â”€ pipeline.py          # ImplementaciÃ³n de Pipeline

tests/
â”œâ”€â”€ conftest.py                  # Fixtures de pruebas
â”œâ”€â”€ test_negative_cases.py       # Tests de manejo de errores
â”œâ”€â”€ test_split_stratified_ab.py  # Tests A/B de divisiÃ³n de datos
â”œâ”€â”€ test_minmax_ab.py           # Tests A/B de MinMaxScaler
â”œâ”€â”€ test_random_forest_ab.py    # Tests A/B de RandomForest
â””â”€â”€ test_pipeline_ab.py         # Tests A/B de Pipeline
```

## ğŸ“ Aspectos Educativos Destacados

### ImplementaciÃ³n de Random Forest
Nuestro RandomForest incluye comentarios detallados explicando:
- **Muestreo Bootstrap**: CÃ³mo el bagging reduce el sobreajuste
- **SelecciÃ³n Aleatoria de CaracterÃ­sticas**: Por quÃ© `sqrt(n_features)` en cada divisiÃ³n
- **VotaciÃ³n por MayorÃ­a**: Combinando predicciones de mÃºltiples Ã¡rboles
- **ConstrucciÃ³n de Ãrboles de DecisiÃ³n**: DivisiÃ³n recursiva con impureza de Gini

### Patrones de DiseÃ±o
- **Clases Mixin**: `ClassifierMixin`, `TransformerMixin`
- **Clases Base Abstractas**: `Estimator` con `fit`/`predict` requeridos
- **Utilidades de ValidaciÃ³n**: VerificaciÃ³n de entrada centralizada
- **Aleatoriedad Reproducible**: GestiÃ³n adecuada de semillas

## ğŸ” Resultados de Tests A/B

Estado actual de los tests: **Todos los tests pasando** âœ…

- DivisiÃ³n de datos: Coincidencia perfecta de formas y proporciones
- MinMaxScaler: Paridad exacta con scikit-learn
- RandomForest: Paridad funcional dentro de la tolerancia (Â±0.25)
- Pipeline: Paridad funcional dentro de la tolerancia (Â±0.20)
- Manejo de errores: ValidaciÃ³n exhaustiva

## ğŸš§ PrÃ³ximamente

- [ ] MÃ¡s mÃ©todos de ensamble (GradientBoosting, AdaBoost)
- [ ] Utilidades de validaciÃ³n cruzada (KFold, cross_val_score)
- [ ] MÃ©todos de selecciÃ³n de caracterÃ­sticas
- [ ] Transformadores de preprocesamiento adicionales (StandardScaler, etc.)

## ğŸ¤ Contribuir

Este es un proyecto educativo. SiÃ©ntete libre de:
1. Hacer fork del repositorio
2. Ejecutar tests con `make test`
3. Implementar componentes adicionales
4. Agregar tests mÃ¡s exhaustivos

## ğŸ“„ Licencia

Licencia MIT - Libre para usar con fines educativos.

---

**Hecho con â¤ï¸ para aprender los fundamentos del aprendizaje automÃ¡tico**